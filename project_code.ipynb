{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "b01887f42de9543c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Installing Dependencies",
   "id": "b400d6e7af14291"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T16:47:43.675837Z",
     "start_time": "2025-11-18T16:47:39.852792Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\bfkiw\\anaconda3\\lib\\site-packages (2.3.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\bfkiw\\anaconda3\\lib\\site-packages (1.26.4)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\bfkiw\\anaconda3\\lib\\site-packages (1.4.2)\n",
      "Requirement already satisfied: ucimlrepo in c:\\users\\bfkiw\\anaconda3\\lib\\site-packages (0.0.7)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\bfkiw\\anaconda3\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\bfkiw\\anaconda3\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\bfkiw\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\bfkiw\\anaconda3\\lib\\site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\bfkiw\\anaconda3\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\bfkiw\\anaconda3\\lib\\site-packages (from scikit-learn) (2.2.0)\n",
      "Requirement already satisfied: certifi>=2020.12.5 in c:\\users\\bfkiw\\anaconda3\\lib\\site-packages (from ucimlrepo) (2025.11.12)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\bfkiw\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    }
   ],
   "execution_count": 3,
   "source": [
    "#install libraries for colab compatability\n",
    "!pip install pandas numpy scikit-learn ucimlrepo"
   ],
   "id": "fbc121e30a2defb3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Downloading Dataset/Describing Variables",
   "id": "8463e9349fe1d9a9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from ucimlrepo import fetch_ucirepo \n",
    "  \n",
    "# fetch dataset \n",
    "student_performance = fetch_ucirepo(id=320) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "X = student_performance.data.features \n",
    "y = student_performance.data.targets \n",
    "  \n",
    "# metadata \n",
    "print(student_performance.metadata) \n",
    "  \n",
    "# variable information \n",
    "print(student_performance.variables) "
   ],
   "id": "a48c428081462539"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Cleaning Data",
   "id": "4447ef51a5c60ced"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T16:38:57.368522Z",
     "start_time": "2025-11-18T16:38:56.071215Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "# check missing values\n",
    "print(\"Missing values per column: \")\n",
    "print(X.isna().sum())\n",
    "\n",
    "# drop duplicates\n",
    "X = X.drop_duplicates()\n",
    "y = y.loc[X.index]\n",
    "\n",
    "# drop G1 and G2 to avoid target leakage, as these are just the semester grades that make up final grade\n",
    "if {\"G1\",\"G2\"}.issubset(X.columns):\n",
    "    X = X.drop(columns=[\"G1\",\"G2\"])\n",
    "\n",
    "# drop rows with missing values\n",
    "X = X.dropna()\n",
    "y = y.loc[X.index]\n",
    "\n",
    "# convert yes/no columns to 0/1\n",
    "binary_cols = [\"schoolsup\",\"famsup\",\"paid\",\"activities\",\"nursery\",\n",
    "               \"higher\",\"internet\",\"romantic\"]\n",
    "for col in binary_cols:\n",
    "    if col in X.columns:\n",
    "        X[col] = X[col].map({\"yes\": 1, \"no\": 0})\n",
    "\n",
    "# convert simple ordinal categories (LE3 is confusing for example)\n",
    "if \"famsize\" in X.columns:\n",
    "    X[\"famsize\"] = X[\"famsize\"].map({\"LE3\": 0, \"GT3\": 1})\n",
    "if \"address\" in X.columns:\n",
    "    X[\"address\"] = X[\"address\"].map({\"U\": 1, \"R\": 0})\n",
    "\n",
    "# clip outliers in absences (some are abnormally high at > 100)\n",
    "if \"absences\" in X.columns:\n",
    "    X[\"absences\"] = X[\"absences\"].clip(upper=40)\n",
    "\n",
    "# group rare job categories to limit number of categorical values\n",
    "job_cols = [\"Mjob\",\"Fjob\"]\n",
    "for col in job_cols:\n",
    "    if col in X.columns:\n",
    "        counts = X[col].value_counts()\n",
    "        rare = counts[counts < 10].index\n",
    "        X[col] = X[col].replace(rare, \"other\")\n",
    "\n",
    "# group rare \"reason\" and \"guardian\" categories to limit number of categorical values\n",
    "rare_group_cols = [\"reason\",\"guardian\"]\n",
    "for col in rare_group_cols:\n",
    "    if col in X.columns:\n",
    "        counts = X[col].value_counts()\n",
    "        rare = counts[counts < 10].index\n",
    "        X[col] = X[col].replace(rare, \"other\")\n",
    "\n",
    "# one-hot encode remaining categoricals\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "# check zero-variance columns\n",
    "zero_var = X.columns[X.nunique() <= 1]\n",
    "print(\"Zero variance columns:\", list(zero_var))\n",
    "\n",
    "# realign y after all X cleaning\n",
    "y = y.loc[X.index]\n",
    "\n",
    "# scale numeric values\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# train/test 80/20 split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.2, random_state=42\n",
    ")\n"
   ],
   "id": "1d143029f87f839c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values per column: \n",
      "school        0\n",
      "sex           0\n",
      "age           0\n",
      "address       0\n",
      "famsize       0\n",
      "Pstatus       0\n",
      "Medu          0\n",
      "Fedu          0\n",
      "Mjob          0\n",
      "Fjob          0\n",
      "reason        0\n",
      "guardian      0\n",
      "traveltime    0\n",
      "studytime     0\n",
      "failures      0\n",
      "schoolsup     0\n",
      "famsup        0\n",
      "paid          0\n",
      "activities    0\n",
      "nursery       0\n",
      "higher        0\n",
      "internet      0\n",
      "romantic      0\n",
      "famrel        0\n",
      "freetime      0\n",
      "goout         0\n",
      "Dalc          0\n",
      "Walc          0\n",
      "health        0\n",
      "absences      0\n",
      "dtype: int64\n",
      "k=1 predictions (first 10): [[16. 14. 14.]\n",
      " [15. 16. 17.]\n",
      " [15. 14. 15.]\n",
      " [15. 16. 17.]\n",
      " [13. 14. 13.]\n",
      " [13. 14. 14.]\n",
      " [14. 14. 14.]\n",
      " [ 4.  8.  8.]\n",
      " [11. 12. 12.]\n",
      " [12. 12. 12.]]\n",
      "k=3 predictions (first 10): [[15.         14.         14.66666667]\n",
      " [13.33333333 14.         15.66666667]\n",
      " [13.66666667 13.33333333 14.33333333]\n",
      " [12.         12.33333333 13.66666667]\n",
      " [12.33333333 12.66666667 12.33333333]\n",
      " [14.33333333 14.66666667 15.33333333]\n",
      " [16.         16.33333333 16.33333333]\n",
      " [ 8.         11.         11.33333333]\n",
      " [12.33333333 11.66666667 12.        ]\n",
      " [10.66666667 11.         11.33333333]]\n",
      "k=5 predictions (first 10): [[13.6 13.2 13.8]\n",
      " [13.4 14.6 15.8]\n",
      " [14.2 14.2 14.8]\n",
      " [13.2 13.  14.2]\n",
      " [12.  12.2 12.2]\n",
      " [13.8 13.8 14.4]\n",
      " [13.4 14.2 14.2]\n",
      " [ 8.6 10.2 10.4]\n",
      " [13.6 13.4 13.8]\n",
      " [11.4 11.8 12. ]]\n",
      "k=7 predictions (first 10): [[13.71428571 13.71428571 14.28571429]\n",
      " [12.71428571 13.28571429 14.28571429]\n",
      " [14.28571429 14.         14.42857143]\n",
      " [12.57142857 12.28571429 13.28571429]\n",
      " [11.57142857 11.85714286 11.71428571]\n",
      " [13.57142857 13.57142857 14.42857143]\n",
      " [13.71428571 14.28571429 14.28571429]\n",
      " [ 8.28571429  9.42857143  9.57142857]\n",
      " [12.85714286 12.57142857 13.        ]\n",
      " [11.57142857 11.85714286 12.28571429]]\n",
      "k=9 predictions (first 10): [[13.77777778 14.11111111 14.55555556]\n",
      " [12.66666667 13.11111111 14.        ]\n",
      " [13.55555556 13.55555556 14.11111111]\n",
      " [12.77777778 12.77777778 13.55555556]\n",
      " [10.88888889 10.88888889 11.11111111]\n",
      " [13.44444444 13.33333333 14.11111111]\n",
      " [13.11111111 13.66666667 13.55555556]\n",
      " [ 8.77777778  9.66666667  9.88888889]\n",
      " [12.66666667 12.66666667 13.11111111]\n",
      " [11.11111111 11.22222222 11.55555556]]\n",
      "k=11 predictions (first 10): [[13.36363636 13.63636364 14.09090909]\n",
      " [13.         13.45454545 14.45454545]\n",
      " [13.63636364 13.81818182 14.36363636]\n",
      " [12.27272727 12.36363636 13.18181818]\n",
      " [11.18181818 11.09090909 11.36363636]\n",
      " [12.63636364 12.63636364 13.45454545]\n",
      " [13.27272727 13.63636364 13.63636364]\n",
      " [ 9.18181818 10.45454545 10.72727273]\n",
      " [12.54545455 12.72727273 13.09090909]\n",
      " [11.27272727 11.18181818 11.54545455]]\n",
      "k=15 predictions (first 10): [[12.8        12.8        13.26666667]\n",
      " [13.13333333 13.6        14.53333333]\n",
      " [13.         13.26666667 13.8       ]\n",
      " [12.46666667 12.93333333 13.6       ]\n",
      " [11.4        11.2        11.66666667]\n",
      " [12.53333333 12.6        13.4       ]\n",
      " [12.73333333 12.93333333 13.26666667]\n",
      " [ 9.46666667 10.2        10.53333333]\n",
      " [11.93333333 12.26666667 12.86666667]\n",
      " [11.4        11.4        11.73333333]]\n",
      "k=21 predictions (first 10): [[13.23809524 13.33333333 13.80952381]\n",
      " [13.38095238 13.66666667 14.47619048]\n",
      " [13.         13.14285714 13.66666667]\n",
      " [12.0952381  12.52380952 13.        ]\n",
      " [11.76190476 11.52380952 12.        ]\n",
      " [12.42857143 12.71428571 13.33333333]\n",
      " [12.52380952 12.76190476 13.23809524]\n",
      " [ 9.85714286 10.47619048 10.71428571]\n",
      " [11.80952381 12.28571429 12.80952381]\n",
      " [11.47619048 11.52380952 11.9047619 ]]\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Training KNN Model",
   "id": "5448b0be7815d37b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# run kNN with a variety of K values\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "k_values = [1, 3, 5, 7, 9, 11, 15, 21]\n",
    "\n",
    "for k in k_values:\n",
    "    knn = KNeighborsRegressor(n_neighbors=k)\n",
    "    knn.fit(X_train, y_train)\n",
    "    preds = knn.predict(X_test)\n",
    "    print(f\"k={k} predictions (first 10): {preds[:10]}\")"
   ],
   "id": "b388fd0d812cfd72"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
